#!/usr/bin/env python
# coding: utf-8

# This file is dependent on processed data. The processed data can be generated by running svd_w2v2.ipynb
# Make sure the script output is redirected to a file to capture printed output

import librosa
from transformers import (
    Wav2Vec2ForCTC,
    Wav2Vec2Processor,
    Wav2Vec2Config,
)
import torch
import pandas as pd
from pycaret.classification import *
import numpy as np
import seaborn as sns
from matplotlib import pyplot
import copy
import random
import os

from sklearn.metrics import accuracy_score
from sklearn.metrics import roc_auc_score
from sklearn.model_selection import StratifiedKFold
from hyperopt import fmin, tpe, hp, STATUS_OK, Trials
from sklearn.model_selection import train_test_split

import warnings
warnings.filterwarnings('ignore')

def set_seed(seed = 0):
    np.random.seed(seed)
    random_state = np.random.RandomState(seed)
    random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    os.environ['PYTHONHASHSEED'] = str(seed)
    return random_state

seed=1112
random_state = set_seed(seed)
# Update path of peocessed csv
processed_df = pd.read_csv(<PATH TO PROCESSED CSV>)

train, test = train_test_split(processed_df, test_size=0.2)
print(train.shape)
print(test.shape)

clf = setup(train, target='target', session_id=seed, fix_imbalance=True, use_gpu=True, n_jobs=14, silent=True)
get_all_trained = compare_models(n_select=15, exclude=['xgboost', 'svm', 'ridge'])

X = copy.deepcopy(train)
X.drop(columns=['target'], axis=1, inplace=True)
y = copy.deepcopy(train['target'])
print(X.shape, type(X))
print(y.shape, type(y))

def cross_val_score(estimator, n_splits=5, random_state=seed):
    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)
    cv_iter = list(cv.split(X, y))
    scores = []
    for train_index, test_index in cv_iter:
        y_true = y.iloc[test_index]
        y_pred = estimator.predict(X.iloc[test_index,:].values)
        scores.append(accuracy_score(y_true, y_pred))
    return np.array(scores).mean()

def hyperopt_train_test(estimator_list):
    estimator = blend_models(estimator_list=[get_all_trained[i] for i in estimator_list], method = 'soft', fold=3)
    return cross_val_score(estimator).mean()

def optimise(params):
    estimator_list = []
    for key, val in params.items():
        if val == 1:
            estimator_list.append(int(key))
    acc = hyperopt_train_test(estimator_list)
    return {'loss': -acc, 'status': STATUS_OK}

model_selection_space = {
    '0': hp.choice('0', [0, 1]),
    '1': hp.choice('1', [0, 1]),
    '2': hp.choice('2', [0, 1]),
    '3': hp.choice('3', [0, 1]),
    '4': hp.choice('4', [0, 1]),
    '5': hp.choice('5', [0, 1]),
    '6': hp.choice('6', [0, 1]),
    '7': hp.choice('7', [0, 1]),
    '8': hp.choice('8', [0, 1]),
    '9': hp.choice('9', [0, 1]),
    '10': hp.choice('10', [0, 1]),
    '11': hp.choice('11', [0, 1])
}

blend_trials = Trials()
blend_best = fmin(optimise, model_selection_space, algo=tpe.suggest, max_evals=21, trials=blend_trials, rstate=random_state)
estimators_for_blend = []
for key, val in blend_best.items():
    if val == 1:
        estimators_for_blend.append(int(key))
print("* blend_best", blend_best)
print("* estimators_for_blend", estimators_for_blend)
for i in estimators_for_blend:
    print("* models for blend", get_all_trained[i])
blend_estimator = blend_models(estimator_list=[get_all_trained[i] for i in estimators_for_blend], method = 'soft', fold=5)

X = copy.deepcopy(test)
X.drop(columns=['target'], axis=1, inplace=True)
y = copy.deepcopy(test['target'])

y_pred = blend_estimator.predict(X)
y_proba = blend_estimator.predict_proba(X)[:,1]
print('* Blend model accuracy: ', accuracy_score(y, y_pred))
print('* Blend model AUC: ', roc_auc_score(y, y_proba))
model, path = save_model(blend_estimator, 'blend_estimator')
print('* blending model saved as ', path)




X = copy.deepcopy(train)
X.drop(columns=['target'], axis=1, inplace=True)
y = copy.deepcopy(train['target'])
print(X.shape, type(X))
print(y.shape, type(y))

def cross_val_score(estimator, n_splits=5, random_state=seed):
    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)
    cv_iter = list(cv.split(X, y))
    scores = []
    for train_index, test_index in cv_iter:
        y_true = y.iloc[test_index]
        y_pred = estimator.predict(X.iloc[test_index,:].values)
        scores.append(accuracy_score(y_true, y_pred))
    return np.array(scores).mean()

def hyperopt_train_test(estimator_list, meta_index):
    estimator = stack_models(estimator_list=[get_all_trained[i] for i in estimator_list], fold=3, meta_model=get_all_trained[meta_index])
    return cross_val_score(estimator).mean()

def optimise(params):
    meta_index = params.pop('meta')
    estimator_list = []
    for key, val in params.items():
        if val == 1:
            estimator_list.append(int(key))
    acc = hyperopt_train_test(estimator_list, meta_index)
    return {'loss': -acc, 'status': STATUS_OK}

model_selection_space = {
    '0': hp.choice('0', [0, 1]),
    '1': hp.choice('1', [0, 1]),
    '2': hp.choice('2', [0, 1]),
    '3': hp.choice('3', [0, 1]),
    '4': hp.choice('4', [0, 1]),
    '5': hp.choice('5', [0, 1]),
    '6': hp.choice('6', [0, 1]),
    '7': hp.choice('7', [0, 1]),
    '8': hp.choice('8', [0, 1]),
    '9': hp.choice('9', [0, 1]),
    '11': hp.choice('10', [0, 1]),
    '11': hp.choice('11', [0, 1]),
    'meta': hp.choice('meta', [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])
}

stack_trials = Trials()
stack_best = fmin(optimise, model_selection_space, algo=tpe.suggest, max_evals=21, trials=stack_trials, rstate=random_state)
estimators_for_stack = []
meta_index = stack_best.pop('meta')
for key, val in stack_best.items():
    if val == 1:
        estimators_for_stack.append(int(key))
print("* stack_best", stack_best)
print("* stack_meta", meta_index)
print("* estimators_for_stack", estimators_for_stack)
for i in estimators_for_stack:
    print("* models for stack", get_all_trained[i])
print("* meta model for stack", get_all_trained[meta_index])
stacked_estimator = stack_models(estimator_list=[get_all_trained[i] for i in estimators_for_stack], fold=5, meta_model=get_all_trained[meta_index])

X = copy.deepcopy(test)
X.drop(columns=['target'], axis=1, inplace=True)
y = copy.deepcopy(test['target'])

y_pred = stacked_estimator.predict(X)
y_proba = stacked_estimator.predict_proba(X)[:,1]
print('* Stack model accuracy: ', accuracy_score(y, y_pred))
print('* Stack model AUC: ', roc_auc_score(y, y_proba))
model, path = save_model(stacked_estimator, 'stacked_estimator')
print('* stacking model saved as ', path)

# def Find_Optimal_Cutoff(target, predicted):
#     fpr, tpr, threshold = roc_curve(target, predicted)
#     i = np.arange(len(tpr)) 
#     roc = pd.DataFrame({'tf' : pd.Series(tpr-(1-fpr), index=i), 'threshold' : pd.Series(threshold, index=i)})
#     roc_t = roc.iloc[(roc.tf).abs().argsort()[:1]]

#     return list(roc_t['threshold']) 

# X = copy.deepcopy(train)
# X.drop(columns=['target'], axis=1, inplace=True)
# y = copy.deepcopy(train['target'])

# y_proba = blend_estimator.predict_proba(X)[:,1]
# threshold = Find_Optimal_Cutoff(y, y_proba)

# X = copy.deepcopy(test)
# X.drop(columns=['target'], axis=1, inplace=True)
# y = copy.deepcopy(test['target'])

# y_pred = blend_estimator.predict(X)
# y_proba = blend_estimator.predict_proba(X)[:,1]
# print('='*100)
# print('Accuracy with default threshold: ', accuracy_score(y, y_pred))
# print('Accuracy with optimal threshold: ', accuracy_score(y, [1 if prob >= threshold else 0 for prob in y_proba]))
# print('='*100)